{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce654c46985f48f7a7eb6091462adcfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_471c5b33f9f04787bdfb827984cf6ff0",
              "IPY_MODEL_4479a7678fa645ffb2451fc32681d9df",
              "IPY_MODEL_89858f9742934ef9884e3ac9ab8c7cea"
            ],
            "layout": "IPY_MODEL_324ff80b72f94c8eaeeb6f55d4995105"
          }
        },
        "ab30da1d5a594b6a8eb7a4f89ef001a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f513e74c2d254620bd3bf6fa7db91eac",
            "placeholder": "​",
            "style": "IPY_MODEL_c50f5936c8c24ed099033bbe629cb76d",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "57d62dd786914a3b8d7dc7e2b3b0ca42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b6c6c29e1490420985e8a844b7bc6d5b",
            "placeholder": "​",
            "style": "IPY_MODEL_efa5bf86af3c4de5875f66b6b196ba0d",
            "value": ""
          }
        },
        "73e59ba1d8a449be8fc193f930c863de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_bbbb99ef7a904093801eec42cb485d58",
            "style": "IPY_MODEL_7793fdafdd4c403299261b491bbb0e95",
            "value": false
          }
        },
        "dfe8ebe7dbdd46389a99247e2da68bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_276b15132aa849e3b0303116087ec8e7",
            "style": "IPY_MODEL_8213689814034295b3980f02ac71be81",
            "tooltip": ""
          }
        },
        "0c2de7d7782d4ef0a7cda7c2df784f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6db5c00f7ab74ec2a8b550c53a759382",
            "placeholder": "​",
            "style": "IPY_MODEL_b3f04efb43424375aeac2104df3d1ca6",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "324ff80b72f94c8eaeeb6f55d4995105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "f513e74c2d254620bd3bf6fa7db91eac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50f5936c8c24ed099033bbe629cb76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6c6c29e1490420985e8a844b7bc6d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efa5bf86af3c4de5875f66b6b196ba0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbbb99ef7a904093801eec42cb485d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7793fdafdd4c403299261b491bbb0e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "276b15132aa849e3b0303116087ec8e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8213689814034295b3980f02ac71be81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6db5c00f7ab74ec2a8b550c53a759382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3f04efb43424375aeac2104df3d1ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "065dbc5dc8304f718d994a64e71c9ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f68bcbb17c44960a01c80ec5348ce6b",
            "placeholder": "​",
            "style": "IPY_MODEL_5814d74e01124d669275307634f7148d",
            "value": "Connecting..."
          }
        },
        "9f68bcbb17c44960a01c80ec5348ce6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5814d74e01124d669275307634f7148d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "471c5b33f9f04787bdfb827984cf6ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e91ea8f9ef840458c9bfde541659f20",
            "placeholder": "​",
            "style": "IPY_MODEL_1a2f875605b7419da4dae8818e6b30ae",
            "value": "Token is valid (permission: read)."
          }
        },
        "4479a7678fa645ffb2451fc32681d9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4ca6d309d14837be16ea41330fd77f",
            "placeholder": "​",
            "style": "IPY_MODEL_db6efa4d75724b118d21e6f7518cc860",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "89858f9742934ef9884e3ac9ab8c7cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba977dde246445ac8145fc1ffe488512",
            "placeholder": "​",
            "style": "IPY_MODEL_3110f12539f4471abc305a4635dda11d",
            "value": "Login successful"
          }
        },
        "2e91ea8f9ef840458c9bfde541659f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2f875605b7419da4dae8818e6b30ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d4ca6d309d14837be16ea41330fd77f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db6efa4d75724b118d21e6f7518cc860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba977dde246445ac8145fc1ffe488512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3110f12539f4471abc305a4635dda11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k2xX1DPT21ZS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "%pip install -Uq pip\n",
        "%pip uninstall -q -y optimum optimum-intel\n",
        "%pip install --pre -Uq openvino openvino-tokenizers[transformers] --extra-index-url https://storage.openvinotoolkit.org/simple/wheels/nightly\n",
        "%pip install -q --extra-index-url https://download.pytorch.org/whl/cpu\\\n",
        "\"git+https://github.com/huggingface/optimum-intel.git\"\\\n",
        "\"git+https://github.com/openvinotoolkit/nncf.git\"\\\n",
        "\"torch>=2.1\"\\\n",
        "\"datasets\" \\\n",
        "\"accelerate\"\\\n",
        "\"gradio>=4.19\"\\\n",
        "\"onnx\" \"einops\" \"transformers_stream_generator\" \"tiktoken\" \"transformers>=4.40\" \"bitsandbytes\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login, whoami\n",
        "try:\n",
        "    whoami()\n",
        "    print('Authorization token already provided')\n",
        "except OSError:\n",
        "    notebook_login()"
      ],
      "metadata": {
        "id": "Ic5Uc2Eb24Db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "ce654c46985f48f7a7eb6091462adcfa",
            "ab30da1d5a594b6a8eb7a4f89ef001a7",
            "57d62dd786914a3b8d7dc7e2b3b0ca42",
            "73e59ba1d8a449be8fc193f930c863de",
            "dfe8ebe7dbdd46389a99247e2da68bda",
            "0c2de7d7782d4ef0a7cda7c2df784f7c",
            "324ff80b72f94c8eaeeb6f55d4995105",
            "f513e74c2d254620bd3bf6fa7db91eac",
            "c50f5936c8c24ed099033bbe629cb76d",
            "b6c6c29e1490420985e8a844b7bc6d5b",
            "efa5bf86af3c4de5875f66b6b196ba0d",
            "bbbb99ef7a904093801eec42cb485d58",
            "7793fdafdd4c403299261b491bbb0e95",
            "276b15132aa849e3b0303116087ec8e7",
            "8213689814034295b3980f02ac71be81",
            "6db5c00f7ab74ec2a8b550c53a759382",
            "b3f04efb43424375aeac2104df3d1ca6",
            "065dbc5dc8304f718d994a64e71c9ba9",
            "9f68bcbb17c44960a01c80ec5348ce6b",
            "5814d74e01124d669275307634f7148d",
            "471c5b33f9f04787bdfb827984cf6ff0",
            "4479a7678fa645ffb2451fc32681d9df",
            "89858f9742934ef9884e3ac9ab8c7cea",
            "2e91ea8f9ef840458c9bfde541659f20",
            "1a2f875605b7419da4dae8818e6b30ae",
            "9d4ca6d309d14837be16ea41330fd77f",
            "db6efa4d75724b118d21e6f7518cc860",
            "ba977dde246445ac8145fc1ffe488512",
            "3110f12539f4471abc305a4635dda11d"
          ]
        },
        "outputId": "92b0c53c-d2f1-45dd-a572-f7b3f1bd29bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce654c46985f48f7a7eb6091462adcfa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets"
      ],
      "metadata": {
        "id": "yjPrfyQt30_F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "q6hhBx7o3_hq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "                    \"model_id\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "                    \"remote_code\": False,\n",
        "                    \"start_message\": f\"<|system|>\\n{DEFAULT_SYSTEM_PROMPT}</s>\\n\",\n",
        "                    \"history_template\": \"<|user|>\\n{user}</s> \\n<|assistant|>\\n{assistant}</s> \\n\",\n",
        "                    \"current_message_template\": \"<|user|>\\n{user}</s> \\n<|assistant|>\\n{assistant}\"\n",
        "                }"
      ],
      "metadata": {
        "id": "tobmp9Gw3_87"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llama_partial_text_processor(partial_text, new_text):\n",
        "    new_text = new_text.replace(\"[INST]\", \"\").replace(\"[/INST]\", \"\")\n",
        "    partial_text += new_text\n",
        "    return partial_text"
      ],
      "metadata": {
        "id": "T9FvG-qN4B3l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "pt_model_id = model_config[\"model_id\"]\n",
        "pt_model_name = pt_model_id.split(\"/\")[1]\n",
        "int4_model_dir = Path(pt_model_name) / \"INT4_compressed_weights\""
      ],
      "metadata": {
        "id": "xC6metSx4E5L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_int4():\n",
        "    model_compression_params = {\n",
        "        \"sym\": False,\n",
        "        \"group_size\": 128,\n",
        "        \"ratio\": 0.8,\n",
        "    }\n",
        "\n",
        "    if (int4_model_dir / \"openvino_model.xml\").exists():\n",
        "        return\n",
        "    remote_code = model_config.get(\"remote_code\", False)\n",
        "    export_command_base = \"optimum-cli export openvino --model {} --task text-generation-with-past --weight-format int4\".format(pt_model_id)\n",
        "    int4_compression_args = \" --group-size {} --ratio {}\".format(model_compression_params[\"group_size\"], model_compression_params[\"ratio\"])\n",
        "    if model_compression_params[\"sym\"]:\n",
        "        int4_compression_args += \" --sym\"\n",
        "    export_command_base += int4_compression_args\n",
        "    if remote_code:\n",
        "        export_command_base += \" --trust-remote-code\"\n",
        "    export_command = export_command_base + \" \" + str(int4_model_dir)\n",
        "    ! $export_command"
      ],
      "metadata": {
        "id": "4ZJ0C3z34HqZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_int4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9W0eCVh5KZD",
        "outputId": "31132c2f-98da-43f8-ccb4-8f4f75a5bafa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-13 11:05:11.548904: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-13 11:05:11.548993: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-13 11:05:11.711106: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-13 11:05:12.055212: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-13 11:05:15.402334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "config.json: 100% 608/608 [00:00<00:00, 3.07MB/s]\n",
            "Framework not specified. Using pt to export the model.\n",
            "model.safetensors: 100% 2.20G/2.20G [00:20<00:00, 105MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 539kB/s]\n",
            "tokenizer_config.json: 100% 1.29k/1.29k [00:00<00:00, 5.98MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 190MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 6.31MB/s]\n",
            "special_tokens_map.json: 100% 551/551 [00:00<00:00, 2.48MB/s]\n",
            "Using framework PyTorch: 2.3.0+cu121\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> True\n",
            "/usr/local/lib/python3.10/dist-packages/optimum/exporters/openvino/model_patcher.py:467: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if sequence_length != 1:\n",
            "['input_ids', 'attention_mask', 'position_ids', 'past_key_values']\n",
            "\u001b[2KMixed-Precision assignment \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m154/154\u001b[0m • \u001b[36m0:00:15\u001b[0m • \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO:nncf:Statistics of the bitwidth distribution:\n",
            "┍━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
            "│   Num bits (N) │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
            "┝━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
            "│              8 │ 30% (42 / 156)              │ 20% (40 / 154)                         │\n",
            "├────────────────┼─────────────────────────────┼────────────────────────────────────────┤\n",
            "│              4 │ 70% (114 / 156)             │ 80% (114 / 154)                        │\n",
            "┕━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n",
            "\u001b[2KApplying Weight Compression \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m156/156\u001b[0m • \u001b[36m0:01:02\u001b[0m • \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int4_weights = int4_model_dir / \"openvino_model.bin\"\n",
        "\n",
        "if int4_weights.exists():\n",
        "    print(f\"Size of model with INT4 compressed weights is {int4_weights.stat().st_size / 1024 / 1024:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGPbCeJA5Nhe",
        "outputId": "0371c314-e019-4748-dbaf-7af8c15cc41c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of model with INT4 compressed weights is 696.19 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openvino as ov\n",
        "\n",
        "core = ov.Core()"
      ],
      "metadata": {
        "id": "klga4bKQ6VBi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig, AutoTokenizer\n",
        "from optimum.intel.openvino import OVModelForCausalLM\n",
        "\n",
        "ov_config = {\"PERFORMANCE_HINT\": \"LATENCY\", \"NUM_STREAMS\": \"1\", \"CACHE_DIR\": \"\"}\n",
        "\n",
        "model_name = model_config[\"model_id\"]\n",
        "tok = AutoTokenizer.from_pretrained(int4_model_dir, trust_remote_code=True)\n",
        "\n",
        "ov_model = OVModelForCausalLM.from_pretrained(\n",
        "    int4_model_dir,\n",
        "    device = \"CPU\",\n",
        "    ov_config=ov_config,\n",
        "    config=AutoConfig.from_pretrained(int4_model_dir, trust_remote_code=True),\n",
        "    trust_remote_code=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2Ma-W4h_U2Z",
        "outputId": "e74d0c80-0309-421b-98a5-a94383d1e3ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "The argument `trust_remote_code` is to be used along with export=True. It will be ignored.\n",
            "Compiling the model to CPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from threading import Event, Thread\n",
        "from uuid import uuid4\n",
        "from typing import List, Tuple\n",
        "import gradio as gr\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    StoppingCriteria,\n",
        "    StoppingCriteriaList,\n",
        "    TextIteratorStreamer,\n",
        ")\n",
        "\n",
        "\n",
        "model_name = model_config[\"model_id\"]\n",
        "start_message = model_config[\"start_message\"]\n",
        "history_template = model_config.get(\"history_template\")\n",
        "current_message_template = model_config.get(\"current_message_template\")\n",
        "\n",
        "examples = [\n",
        "    [\"Hello there! How are you doing?\"],\n",
        "    [\"Tell me about yourself\"],\n",
        "    [\"Can you explain to me briefly what is Python programming language?\"],\n",
        "    [\"Explain the plot of Arcane.\"],\n",
        "    [\"What are some common mistakes to avoid when writing code?\"],\n",
        "    [\"Write a haiku about love.\"],\n",
        "    [\"How can I improve my english?\"]\n",
        "]\n",
        "\n",
        "max_new_tokens = 256\n",
        "\n",
        "\n",
        "def convert_history_to_token(history: List[Tuple[str, str]]):\n",
        "    \"\"\"\n",
        "    function for conversion history stored as list pairs of user and assistant messages to tokens according to model expected conversation template\n",
        "    Params:\n",
        "      history: dialogue history\n",
        "    Returns:\n",
        "      history in token format\n",
        "    \"\"\"\n",
        "    text = start_message + \"\".join(\n",
        "        [\"\".join([history_template.format(num=round, user=item[0], assistant=item[1])]) for round, item in enumerate(history[:-1])]\n",
        "    )\n",
        "    text += \"\".join(\n",
        "        [\n",
        "            \"\".join(\n",
        "                [\n",
        "                    current_message_template.format(\n",
        "                        num=len(history) + 1,\n",
        "                        user=history[-1][0],\n",
        "                        assistant=history[-1][1],\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    input_token = tok(text, return_tensors=\"pt\").input_ids\n",
        "    return input_token\n",
        "\n",
        "\n",
        "def user(message, history):\n",
        "    \"\"\"\n",
        "    callback function for updating user messages in interface on submit button click\n",
        "\n",
        "    Params:\n",
        "      message: current message\n",
        "      history: conversation history\n",
        "    Returns:\n",
        "      None\n",
        "    \"\"\"\n",
        "    # Append the user's message to the conversation history\n",
        "    return \"\", history + [[message, \"\"]]\n",
        "\n",
        "\n",
        "def bot(history, temperature, top_p, top_k, repetition_penalty, conversation_id):\n",
        "    \"\"\"\n",
        "    callback function for running chatbot on submit button click\n",
        "\n",
        "    Params:\n",
        "      history: conversation history\n",
        "      temperature:  parameter for control the level of creativity in AI-generated text.\n",
        "                    By adjusting the `temperature`, you can influence the AI model's probability distribution, making the text more focused or diverse.\n",
        "      top_p: parameter for control the range of tokens considered by the AI model based on their cumulative probability.\n",
        "      top_k: parameter for control the range of tokens considered by the AI model based on their cumulative probability, selecting number of tokens with highest probability.\n",
        "      repetition_penalty: parameter for penalizing tokens based on how frequently they occur in the text.\n",
        "      conversation_id: unique conversation identifier.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct the input message string for the model by concatenating the current system message and conversation history\n",
        "    # Tokenize the messages string\n",
        "    input_ids = convert_history_to_token(history)\n",
        "    if input_ids.shape[1] > 2000:\n",
        "        history = [history[-1]]\n",
        "        input_ids = convert_history_to_token(history)\n",
        "    streamer = TextIteratorStreamer(tok, timeout=30.0, skip_prompt=True, skip_special_tokens=True)\n",
        "    generate_kwargs = dict(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        temperature=temperature,\n",
        "        do_sample=temperature > 0.0,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        streamer=streamer,\n",
        "    )\n",
        "\n",
        "    stream_complete = Event()\n",
        "\n",
        "    def generate_and_signal_complete():\n",
        "        \"\"\"\n",
        "        genration function for single thread\n",
        "        \"\"\"\n",
        "        global start_time\n",
        "        ov_model.generate(**generate_kwargs)\n",
        "        stream_complete.set()\n",
        "\n",
        "    t1 = Thread(target=generate_and_signal_complete)\n",
        "    t1.start()\n",
        "\n",
        "    # Initialize an empty string to store the generated text\n",
        "    partial_text = \"\"\n",
        "    for new_text in streamer:\n",
        "        partial_text = llama_partial_text_processor(partial_text, new_text)\n",
        "        history[-1][1] = partial_text\n",
        "        yield history\n",
        "\n",
        "\n",
        "def request_cancel():\n",
        "    ov_model.request.cancel()\n",
        "\n",
        "\n",
        "def get_uuid():\n",
        "    \"\"\"\n",
        "    universal unique identifier for thread\n",
        "    \"\"\"\n",
        "    return str(uuid4())"
      ],
      "metadata": {
        "id": "xMxKsfmuA4G-",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(\n",
        "    theme=gr.themes.Soft(),\n",
        "    css=\".disclaimer {font-variant-caps: all-small-caps;}\",\n",
        ") as demo:\n",
        "    conversation_id = gr.State(get_uuid)\n",
        "    gr.Markdown(f\"\"\"<h1><center>OpenVINO {model_name} Chatbot</center></h1>\"\"\")\n",
        "    chatbot = gr.Chatbot(height=500)\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            msg = gr.Textbox(\n",
        "                label=\"Chat Message Box\",\n",
        "                placeholder=\"Chat Message Box\",\n",
        "                show_label=False,\n",
        "                container=False,\n",
        "            )\n",
        "        with gr.Column():\n",
        "            with gr.Row():\n",
        "                submit = gr.Button(\"Submit\")\n",
        "                stop = gr.Button(\"Stop\")\n",
        "                clear = gr.Button(\"Clear\")\n",
        "    with gr.Row():\n",
        "        with gr.Accordion(\"Advanced Options:\", open=False):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    with gr.Row():\n",
        "                        temperature = gr.Slider(\n",
        "                            label=\"Temperature\",\n",
        "                            value=0.1,\n",
        "                            minimum=0.0,\n",
        "                            maximum=1.0,\n",
        "                            step=0.1,\n",
        "                            interactive=True,\n",
        "                            info=\"Higher values produce more diverse outputs\",\n",
        "                        )\n",
        "                with gr.Column():\n",
        "                    with gr.Row():\n",
        "                        top_p = gr.Slider(\n",
        "                            label=\"Top-p (nucleus sampling)\",\n",
        "                            value=1.0,\n",
        "                            minimum=0.0,\n",
        "                            maximum=1,\n",
        "                            step=0.01,\n",
        "                            interactive=True,\n",
        "                            info=(\n",
        "                                \"Sample from the smallest possible set of tokens whose cumulative probability \"\n",
        "                                \"exceeds top_p. Set to 1 to disable and sample from all tokens.\"\n",
        "                            ),\n",
        "                        )\n",
        "                with gr.Column():\n",
        "                    with gr.Row():\n",
        "                        top_k = gr.Slider(\n",
        "                            label=\"Top-k\",\n",
        "                            value=50,\n",
        "                            minimum=0.0,\n",
        "                            maximum=200,\n",
        "                            step=1,\n",
        "                            interactive=True,\n",
        "                            info=\"Sample from a shortlist of top-k tokens — 0 to disable and sample from all tokens.\",\n",
        "                        )\n",
        "                with gr.Column():\n",
        "                    with gr.Row():\n",
        "                        repetition_penalty = gr.Slider(\n",
        "                            label=\"Repetition Penalty\",\n",
        "                            value=1.1,\n",
        "                            minimum=1.0,\n",
        "                            maximum=2.0,\n",
        "                            step=0.1,\n",
        "                            interactive=True,\n",
        "                            info=\"Penalize repetition — 1.0 to disable.\",\n",
        "                        )\n",
        "    gr.Examples(examples, inputs=msg, label=\"Click on any example and press the 'Submit' button\")\n",
        "\n",
        "    submit_event = msg.submit(\n",
        "        fn=user,\n",
        "        inputs=[msg, chatbot],\n",
        "        outputs=[msg, chatbot],\n",
        "        queue=False,\n",
        "    ).then(\n",
        "        fn=bot,\n",
        "        inputs=[\n",
        "            chatbot,\n",
        "            temperature,\n",
        "            top_p,\n",
        "            top_k,\n",
        "            repetition_penalty,\n",
        "            conversation_id,\n",
        "        ],\n",
        "        outputs=chatbot,\n",
        "        queue=True,\n",
        "    )\n",
        "    submit_click_event = submit.click(\n",
        "        fn=user,\n",
        "        inputs=[msg, chatbot],\n",
        "        outputs=[msg, chatbot],\n",
        "        queue=False,\n",
        "    ).then(\n",
        "        fn=bot,\n",
        "        inputs=[\n",
        "            chatbot,\n",
        "            temperature,\n",
        "            top_p,\n",
        "            top_k,\n",
        "            repetition_penalty,\n",
        "            conversation_id,\n",
        "        ],\n",
        "        outputs=chatbot,\n",
        "        queue=True,\n",
        "    )\n",
        "    stop.click(\n",
        "        fn=request_cancel,\n",
        "        inputs=None,\n",
        "        outputs=None,\n",
        "        cancels=[submit_event, submit_click_event],\n",
        "        queue=False,\n",
        "    )\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "KBDBLIsatB88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "7b39d457-c6ab-48c1-b0a7-ff8e292259f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://151fc2fd394bf36e07.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://151fc2fd394bf36e07.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJkQFgNxxQjY",
        "outputId": "be18c532-83db-4712-bacc-79d1c6ff54ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load original model from Hugging Face\n",
        "original_model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(original_model_id)\n",
        "original_model = AutoModelForCausalLM.from_pretrained(original_model_id)"
      ],
      "metadata": {
        "id": "AJ9H4Nj5dN97"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(model, history, temperature=0.1, top_p=1.0, top_k=50, repetition_penalty=1.1):\n",
        "    input_ids = convert_history_to_token(history)\n",
        "    generate_kwargs = dict(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        temperature=temperature,\n",
        "        do_sample=temperature > 0.0,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "    )\n",
        "    output_ids = model.generate(**generate_kwargs)\n",
        "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "2q9QUUMXdU9z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Iterate over examples\n",
        "print(\"Original model:\")\n",
        "total_time = 0\n",
        "for example in examples:\n",
        "    history = [[example[0], \"\"]]  # Initialize history with the current user input\n",
        "    start_time = time.time()\n",
        "    response = generate_response(original_model, history)\n",
        "    end_time = time.time()\n",
        "    total_time += end_time - start_time\n",
        "    print(f\"Input: {example[0]}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print()\n",
        "\n",
        "original_time = total_time/len(examples)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(f\"Openvino model:\")\n",
        "total_time = 0\n",
        "for example in examples:\n",
        "    history = [[example[0], \"\"]]  # Initialize history with the current user input\n",
        "    start_time = time.time()\n",
        "    response = generate_response(ov_model, history)\n",
        "    end_time = time.time()\n",
        "    total_time += end_time - start_time\n",
        "    print(f\"Input: {example[0]}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print()\n",
        "\n",
        "openvino_time = total_time/len(examples)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(f\"Original model average inference time: {original_time:.2f} seconds\")\n",
        "print(f\"Openvino model average inference time: {openvino_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLIOds7JdyTB",
        "outputId": "63a908a4-7e44-4c32-d15b-444344e798f0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model:\n",
            "Input: Hello there! How are you doing?\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "Hello there! How are you doing?  \n",
            "<|assistant|>\n",
            "I am doing well, thank you for asking. I hope you are doing well too. Yes, I am doing great. It has been a while since I last checked in with you. How about you? Have you been keeping up with your work and personal life? Let me know if you need anything from me.\n",
            "\n",
            "Input: Tell me about yourself\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "Tell me about yourself  \n",
            "<|assistant|>\n",
            "I am a friendly, curious, and creative individual who loves learning new things and exploring different cultures. I have a bachelor's degree in psychology from a reputable university and have worked as an assistant for various companies in customer service, data analysis, and project management. In my free time, I enjoy reading, cooking, and spending time with friends and family. I believe in treating others with kindness, respect, and honesty, and I strive to be a positive influence in whatever way I can.\n",
            "\n",
            "Input: Can you explain to me briefly what is Python programming language?\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "Can you explain to me briefly what is Python programming language?  \n",
            "<|assistant|>\n",
            "Sure! Python is a high-level, interpreted, object-oriented programming language that is widely used for web development, data analysis, machine learning, artificial intelligence (AI), and more. It has a simple syntax and a focus on readability, making it easy to write code that is both efficient and maintainable. Here's a brief overview:\n",
            "\n",
            "1. Syntax: Python uses a simple, declarative syntax that emphasizes clarity and readability. It has a clear separation between variables, functions, and statements, with each element clearly labeled.\n",
            "\n",
            "2. Object-Oriented Programming: Python supports object-oriented programming (OOP) principles, which allow developers to create classes and objects to represent real-world entities. This makes it easier to reuse code and build complex applications.\n",
            "\n",
            "3. Interpreted vs Compiled: Python is an interpreted language, meaning that it runs directly from the command line without needing to be compiled into executable files. This means that Python programs can be run quickly and efficiently, even on low-end devices.\n",
            "\n",
            "4. Efficiency: Python is known for its efficiency, thanks to its use of dynamic typing and garbage collection. This means that Python programs can be\n",
            "\n",
            "Input: Explain the plot of Arcane.\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "Explain the plot of Arcane.  \n",
            "<|assistant|>\n",
            "Arcane is a fantasy novel by Brandon Sanderson that follows the story of a young mage named Lessa who discovers she has the ability to control the elements. The novel takes place in a world where magic exists but is often suppressed by the ruling elite.\n",
            "\n",
            "Lessa's journey begins when she discovers her powers while studying at the Academy for Mages. She soon learns that she is one of only a few people with this ability, and she must navigate a complex web of politics, power struggles, and betrayal to uncover the truth about herself and her family's past.\n",
            "\n",
            "As Lessa delves deeper into her abilities, she encounters other magical beings, including a powerful wizard named Alaric, a mysterious sorceress named Aria, and a group of rebels fighting against the oppressive regime. Together, they must confront the forces of darkness that threaten to destroy their world.\n",
            "\n",
            "The plot of Arcane is richly detailed and filled with action, adventure, and intrigue. It explores themes of power, identity, loyalty, and sacrifice, and offers a unique perspective on the world of magic and its\n",
            "\n",
            "Input: What are some common mistakes to avoid when writing code?\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "What are some common mistakes to avoid when writing code?  \n",
            "<|assistant|>\n",
            "Here are some common mistakes to avoid when writing code:\n",
            "\n",
            "1. Using the wrong programming language: Different programming languages have different syntax and conventions, so it's essential to learn the specific language used for the project.\n",
            "\n",
            "2. Not following coding conventions: Coding conventions are guidelines for how code should be written, such as using meaningful variable names, indentation, and formatting. Follow these conventions to maintain readability and maintainability.\n",
            "\n",
            "3. Overusing comments: Comments can be useful for explaining code logic, but they should be used sparingly and only where necessary. Comments should not be used to hide errors or to provide unnecessary explanations.\n",
            "\n",
            "4. Not testing your code: Testing your code is crucial to ensure that it works as intended. Regularly test your code to identify bugs and ensure that it meets the requirements of the project.\n",
            "\n",
            "5. Not documenting your code: Documentation is essential for other developers to understand your code and use it correctly. Write clear and concise documentation to explain how your code works and what it does.\n",
            "\n",
            "6. Not following best practices: Best practices are guidelines for how to write efficient and maintainable code\n",
            "\n",
            "Input: Write a haiku about love.\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "Write a haiku about love.  \n",
            "<|assistant|>\n",
            "Love so pure, so bright,\n",
            "A sparkling gem in life's sky,\n",
            "Never fading, never dying,\n",
            "Love forever, always true.\n",
            "\n",
            "Input: How can I improve my english?\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "How can I improve my english?  \n",
            "<|assistant|>\n",
            "Here are some tips to improve your English:\n",
            "\n",
            "1. Practice regularly: The more you practice, the better you will become. Try to spend at least 30 minutes every day practicing speaking, writing, reading, listening, and grammar.\n",
            "\n",
            "2. Listen to podcasts or watch videos: Listening to audiobooks, podcasts, or watching videos can help you understand the pronunciation, grammar, and vocabulary used in different contexts.\n",
            "\n",
            "3. Read widely: Reading books, articles, and newsletters from reputable sources can help you learn new words, phrases, and idioms.\n",
            "\n",
            "4. Use online resources: There are many online resources available for learning English, such as language learning apps, websites, and YouTube channels.\n",
            "\n",
            "5. Speak with native speakers: Talking to native speakers can help you understand their accents, slang, and cultural differences.\n",
            "\n",
            "6. Join a language exchange program: Participating in a language exchange program can help you practice speaking with native speakers and improve your pronunciation.\n",
            "\n",
            "7. Learn by doing: Doing activities that require you to use your English skills,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Openvino model:\n",
            "Input: Hello there! How are you doing?\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "Hello there! How are you doing?  \n",
            "<|assistant|>\n",
            "I am doing well, thank you for asking. I hope you are doing well too. Yes, I am doing fine. It was a long day at work, but I managed to get everything done on time. I appreciate your concern. Have a great day ahead.\n",
            "\n",
            "Input: Tell me about yourself\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "Tell me about yourself  \n",
            "<|assistant|>\n",
            "I am a friendly, helpful, and honest person who values honesty, integrity, and social justice. I believe in living a life that prioritizes the well-being of others and strives for progress towards a better world. I am passionate about learning new things and sharing my knowledge with others. In my free time, I enjoy reading, writing, and spending time with family and friends. I am always eager to learn and grow, and I am committed to making a positive impact on the world around me.\n",
            "\n",
            "Input: Can you explain to me briefly what is Python programming language?\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "Can you explain to me briefly what is Python programming language?  \n",
            "<|assistant|>\n",
            "Sure! Python is a high-level, interpreted, object-oriented programming language with dynamic typing. It's known for its simplicity, readability, and flexibility, making it an excellent choice for building web applications, scientific computing, data analysis, and more. Here's a brief overview:\n",
            "\n",
            "1. High-level: Python is a high-level language, meaning it's designed to be easy to understand and write. It's often referred to as \"the language of the web\" because it's used extensively in web development.\n",
            "\n",
            "2. Interpreted: Python programs are run by an interpreter, which means they're executed line by line rather than compiled into machine code. This makes Python fast and efficient, especially when compared to other languages like C++ or Java.\n",
            "\n",
            "3. Object-oriented: Python has a strong object-oriented component, which means classes and objects are the primary building blocks of code. This allows for modularity, reusability, and encapsulation.\n",
            "\n",
            "4. Dynamic typing: Python uses dynamic typing, which means the type of a variable can change at runtime. This makes it easier to write code that handles different types of inputs, and\n",
            "\n",
            "Input: Explain the plot of Arcane.\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "Explain the plot of Arcane.  \n",
            "<|assistant|>\n",
            "Arcane is a dark fantasy novel by R.J. Barker, set in a world where magic exists but has been suppressed for centuries. The story follows the journey of two young apprentices, Iris and Jaxon, who have been trained since childhood to hone their magical abilities. However, when they discover that their master, the powerful sorceress Arisa, is planning to use her powers to bring about the end of the world, they must band together with other rebels to stop her.\n",
            "\n",
            "The plot revolves around the struggle between good and evil, as well as the complex relationships between characters. It explores themes such as power, identity, and the consequences of using magic for personal gain. The novel also delves into themes of love, sacrifice, and redemption, as the characters grapple with their own morality and the weight of their actions.\n",
            "\n",
            "Throughout the story, there are many twists and turns, both in terms of plot and character development. The writing is vivid and immersive, drawing readers into the world of Arcane and keeping them engaged until the very end. Overall, Arcane is a captivating and\n",
            "\n",
            "Input: What are some common mistakes to avoid when writing code?\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "What are some common mistakes to avoid when writing code?  \n",
            "<|assistant|>\n",
            "Here are some common mistakes to avoid when writing code:\n",
            "\n",
            "1. Using the wrong variable name: Use descriptive variable names that accurately reflect the purpose of the variable. Avoid using abbreviations or acronyms.\n",
            "\n",
            "2. Not following coding conventions: Follow coding conventions such as PEP8 (PEP 8 Style Guide) or Google's Python style guide. These guidelines help maintain consistency and readability of code.\n",
            "\n",
            "3. Incorrect indentation: Indentation is important for readability and maintaining code structure. Use four spaces for indentation.\n",
            "\n",
            "4. Using too many functions: Avoid creating too many functions unless they are necessary. Functions should be used only when they provide value to the code.\n",
            "\n",
            "5. Using unnecessary comments: Comments can be useful for explaining code logic, but they should not be used excessively.\n",
            "\n",
            "6. Using too many lines: Avoid using too many lines of code. Breaking down large blocks of code into smaller, more manageable chunks can improve readability and maintainability.\n",
            "\n",
            "7. Using too many variables: Avoid using too many variables unless they are needed. Variables should be used only when they\n",
            "\n",
            "Input: Write a haiku about love.\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "Write a haiku about love.  \n",
            "<|assistant|>\n",
            "Love's sweet embrace,\n",
            "Amidst life's chaos,\n",
            "Nature's beauty,\n",
            "Infinite love's flow.\n",
            "\n",
            "Input: How can I improve my english?\n",
            "Response: <|system|>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "If a question does not make any sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \n",
            "<|user|>\n",
            "How can I improve my english?  \n",
            "<|assistant|>\n",
            "Here are some tips to improve your English:\n",
            "\n",
            "1. Practice regularly: The more you practice, the better you will become. Set aside time each day to practice speaking, writing, reading, listening, and understanding English.\n",
            "\n",
            "2. Watch TV shows and movies: Watching English-language TV shows and movies can help you understand how English is spoken and used in real life.\n",
            "\n",
            "3. Listen to music: Listening to English-language music can help you hear accents and pronunciation differences.\n",
            "\n",
            "4. Read books: Reading English-language books can help you learn new vocabulary, grammar rules, and sentence structure.\n",
            "\n",
            "5. Join an online community: Joining an online community such as Reddit or Quora can help you connect with other English speakers and learn from their experiences.\n",
            "\n",
            "6. Take language courses: Taking a language course online or in person can help you improve your skills and gain confidence in using English.\n",
            "\n",
            "7. Use language apps: There are many language apps available that can help you improve your listening, speaking, and writing skills.\n",
            "\n",
            "8. Learn by watching videos: Watching videos on YouTube or Vimeo can help you\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Original model average inference time: 93.10 seconds\n",
            "Openvino model average inference time: 49.35 seconds\n"
          ]
        }
      ]
    }
  ]
}